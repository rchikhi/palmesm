{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "445b6482",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1e67fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43968,\n",
       " ':',\n",
       " [(1,\n",
       "   'DLLHGDESANSLDGGRGDDHLVGAEGDDWLIGGEGADRLEGGAGTDTADYSGAAARIVVGLNVNPLHGPEGGVGYEGEAHGDRLLDIENLVGSAHGDLLHGDDGANRIDGGKGDDVLVGAGGADTLDGGEGSDTASYAGSSARIEIDLLDGVGRGGEAEGDRLSGIENLLGTSHDDLLLGDAKANRIEGGDRGDTLNGRAGDDVLVGGEGGDWLDGGDGIDTADYSAAKGRVVVGLNVNTAWHADGGAGYEGE',\n",
       "   'neg'),\n",
       "  (2,\n",
       "   'TADDSGVPTITWYQVGNGQPADIDAWYEQVNPYLEEKIGAHVNLQVVDWGSWNDRRTMLVQTNDDYDIIFTDMSTYASNVNMGAFADLTDLMANVPGLTDLIPEEYLKACNINGKLYGIPAYKDSSMTNFFVWTKDYVDQYYPDYAEDHDLFSIDEGLRAIYEGTGETPMMLNKDGISCIIGNRYDNFGSGLPAIGVSYYSDDAKVVSVFEQDDVLDQLRQMHTWYNDGLINSDANTLDNFQGMCAVGVAQGW',\n",
       "   'neg'),\n",
       "  (3,\n",
       "   'GIYDAVPYALNLANVPFCGYGGEKDPQLLAATTMQQAAEKLQVPLKLIIGKGMGHAFDPASRNEFMAFHAANVQTGRPKFGTRDRIRFTTQTLKYNRCDWLSIIEMEQSGRPATVESERDAAGILQIRTDNVDLMTLARDITEQVRIDGTLLECRAAAGELLPEVWYRKTVDGWEVVDYQQSRTVSRNVDLNKRPGLQGPIDDAFMSPFICIRGTGQPLHPLPEAWSQRQLDVFQQEFARWMRGDVKVVNDVD',\n",
       "   'neg'),\n",
       "  (4,\n",
       "   'EMIAIFLDLLGYRYDLTHDASDVDLGVKLAKQLVQHPLRNNFLHPLVFWLDRHSDITHDYSDLDTMLELARETVAGLAQNDPSRLDHLRNVAVIHYKRHRITNDLSDLDVCLKILLDVFEKTTTEPARHRIQGNIAKSLLRHYDITKDTSDLNRALQLVENVAINTVRQTVDTEYERPFQLTILAVCLCRRYIITRNCSDIDDALLWQQEAVNVTIKDDPQSKFRLGTLAFCHRLRYDVMGYRTNLDHALRLL',\n",
       "   'neg'),\n",
       "  (5,\n",
       "   'KPVGGFFYQCVDPLCTESRVAECWETLNRNPCTPCKSVCGECKLGFTGANCDQDVNDCDPNPCVAGKCTDTGASSFKCDCFEGATGTRCEVDTDPCNASALAQCAAQHRDPCRRHQGSAACGGCLEGFLPGSGTEAGACVDVCSQDLSKCCSTERAQACTAQQRHSCESGNVSCGACQDGFVEQEGDPWGIQPCAAASLQSDDSKGGLLSSPRCAGIAYKLSGICAIVWVLLGILLFALVCVVAFRHRIHEGL',\n",
       "   'neg')],\n",
       " '..',\n",
       " [(43964,\n",
       "   'ADPANYRAIVITDIISKVFTRAIYNQLVKELDPKILQTQAGFRKKRSPSEHVFVLRQLMEAAREFKQPLCVAFVDIEKAYDGIPRAPLLKVLRRYGASSRLCQLIDILYRKTSARVRIGLVDSDMFDIHTGVKQGCILSTILFNIYLDFAVRQVLPRFQHKGVSWKVSKPLDPRSRTRSSRSNDSSHSSWSALIINHLLYADDTTVIATTYQDLCHMVTDMNAEFLKWGLKISATKTVFACLNGDQVPSTPFL',\n",
       "   'xdxp'),\n",
       "  (43965,\n",
       "   'IKHLSNNFFQAFSRLMNGVRRRNKTKFAEEAVKYKKSFEDEIEASTLERVGDLGTIEEVCKIIQKDPYFFNNQKVAGNKCICYLPHQCVYKQSNGKFRRVHDAKAKPGKGCMCLNDCLNKGPNLIASILHVLLGFRKNKFGFSSDIQKAFPCVEIAEEHRDLLRCLWVENGRVVIYRFARLPFGLKCSPYILSATLRKHLGDNQISESLMTQFIGGCYMDDLISSESTVESMREKKDIITKIFGECGMYFRDW',\n",
       "   'xdxp'),\n",
       "  (43966,\n",
       "   'KIDNNDLPFVYAIPKFHKNPVKFRFITSSVNCSVKPISLVLNKMLDYLMSVVQEKHQQKQDFWVIKNSKEVLNSIKEYKEIPGDYSMATYDFSTLYTSLPQKDLRDTVKKLIQKYITSTFKIKWNGKTLNVTSKIFINTLSFCIDNTYIMFNDGIYKQSIGIPMGANYSPNLANLFLFAFESKYMSNTANKEYFTNSFRYIDDLLSINNPYIDEAIKQIYPPSLSIVNTSIQDSNHTSFLDLDMKVQNNRFNT',\n",
       "   'xdxp'),\n",
       "  (43967,\n",
       "   'HEFNREFDLETHRLLRLAEEPRKLNLAATFEQALRDAPNKHQCRTLPIVDEGGKIRVATVHTASVAWLARSMSAVLFPHLKHFAFSSAILKGEHVKLVNNSPDPLLLFSADFRKSTDPISVSQARRILDGIRRRIPVPSWWDRAVENVITRHAIQLPDGTEIWTECGALMGLGPGWAVLCILNAWAAENAGAPVGSFAVCGDDLIALWTRENIACYRANIRKVMLALNDDKCYCGPYHGVFCEQLVVRTGKYT',\n",
       "   'xdxp'),\n",
       "  (43968,\n",
       "   'NAQNGFCPGRSIFANIHLCNLIQSYLNDTDEEGLLIFLDLEKAFDRVSWTYLHGALKHLNLPEELTEWIGVLYDSDAPPSRRVTINGHVGDYFNINCGNAQGCPLSPILFLFVGEALSRLVQTHPKWEGIKIDGTEHFLSQFADDTVLFLRRFQDLPFMWQVVRTFEQATAMKVNVTKTEGLRCGRLRDSALDWR',\n",
       "   'xdxp')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "data = []\n",
    "for (counter,row) in enumerate(csv.reader(open(\"data/df-lowneg.csv\"))):\n",
    "    if counter == 0: continue\n",
    "    data += [(counter,row[0],row[1])]\n",
    "len(data),\":\",data[:5],\"..\",data[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3bd48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# example from https://github.com/facebookresearch/esm\n",
    "#\n",
    "# abandoned because doesn't run on my comp\n",
    "#\n",
    "#import torch\n",
    "#model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", \"esm2_t6_8M_UR50D\")\n",
    "#batch_converter = alphabet.get_batch_converter()\n",
    "#model.eval()  # disables dropout for deterministic results\n",
    "#batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "#with torch.no_grad():\n",
    "#    results = model(batch_tokens, repr_layers=[6], return_contacts=True)\n",
    "#token_representations = results[\"representations\"][6]\n",
    "## ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0e492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c37f9a4a",
   "metadata": {},
   "source": [
    "\n",
    "# Model training, following https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/protein_language_modeling.ipynb to the T.\n",
    "\n",
    "To use it, make sure you have installed `pip install transformers evaluate datasets requests pandas sklearn`\n",
    "\n",
    "# Skip to next section if you just want to use the pre-trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3645a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/esm2_t6_8M_UR50D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee6315a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DLLHGDESANSLDGGRGDDHLVGAEGDDWLIGGEGADRLEGGAGTDTADYSGAAARIVVGLNVNPLHGPEGGVGYEGEAHGDRLLDIENLVGSAHGDLLHGDDGANRIDGGKGDDVLVGAGGADTLDGGEGSDTASYAGSSARIEIDLLDGVGRGGEAEGDRLSGIENLLGTSHDDLLLGDAKANRIEGGDRGDTLNGRAGDDVLVGGEGGDWLDGGDGIDTADYSAAKGRVVVGLNVNTAWHADGGAGYEGE', 'TADDSGVPTITWYQVGNGQPADIDAWYEQVNPYLEEKIGAHVNLQVVDWGSWNDRRTMLVQTNDDYDIIFTDMSTYASNVNMGAFADLTDLMANVPGLTDLIPEEYLKACNINGKLYGIPAYKDSSMTNFFVWTKDYVDQYYPDYAEDHDLFSIDEGLRAIYEGTGETPMMLNKDGISCIIGNRYDNFGSGLPAIGVSYYSDDAKVVSVFEQDDVLDQLRQMHTWYNDGLINSDANTLDNFQGMCAVGVAQGW', 'GIYDAVPYALNLANVPFCGYGGEKDPQLLAATTMQQAAEKLQVPLKLIIGKGMGHAFDPASRNEFMAFHAANVQTGRPKFGTRDRIRFTTQTLKYNRCDWLSIIEMEQSGRPATVESERDAAGILQIRTDNVDLMTLARDITEQVRIDGTLLECRAAAGELLPEVWYRKTVDGWEVVDYQQSRTVSRNVDLNKRPGLQGPIDDAFMSPFICIRGTGQPLHPLPEAWSQRQLDVFQQEFARWMRGDVKVVNDVD', 'EMIAIFLDLLGYRYDLTHDASDVDLGVKLAKQLVQHPLRNNFLHPLVFWLDRHSDITHDYSDLDTMLELARETVAGLAQNDPSRLDHLRNVAVIHYKRHRITNDLSDLDVCLKILLDVFEKTTTEPARHRIQGNIAKSLLRHYDITKDTSDLNRALQLVENVAINTVRQTVDTEYERPFQLTILAVCLCRRYIITRNCSDIDDALLWQQEAVNVTIKDDPQSKFRLGTLAFCHRLRYDVMGYRTNLDHALRLL', 'KPVGGFFYQCVDPLCTESRVAECWETLNRNPCTPCKSVCGECKLGFTGANCDQDVNDCDPNPCVAGKCTDTGASSFKCDCFEGATGTRCEVDTDPCNASALAQCAAQHRDPCRRHQGSAACGGCLEGFLPGSGTEAGACVDVCSQDLSKCCSTERAQACTAQQRHSCESGNVSCGACQDGFVEQEGDPWGIQPCAAASLQSDDSKGGLLSSPRCAGIAYKLSGICAIVWVLLGILLFALVCVVAFRHRIHEGL'] [0, 0, 0, 0, 0]\n",
      "{'input_ids': [0, 8, 8, 7, 21, 22, 5, 5, 15, 8, 6, 8, 11, 8, 21, 6, 12, 11, 16, 5, 21, 8, 6, 11, 19, 19, 6, 22, 4, 17, 23, 19, 4, 5, 8, 16, 11, 19, 17, 14, 19, 19, 4, 12, 11, 5, 14, 12, 13, 4, 8, 5, 11, 13, 17, 14, 15, 10, 4, 17, 19, 22, 19, 22, 12, 6, 11, 8, 8, 18, 14, 5, 11, 5, 13, 17, 14, 4, 23, 7, 13, 12, 8, 11, 17, 17, 16, 9, 8, 22, 11, 11, 12, 19, 8, 21, 8, 15, 11, 9, 17, 4, 8, 17, 22, 19, 16, 17, 12, 7, 13, 4, 11, 13, 19, 17, 13, 13, 12, 7, 19, 4, 10, 18, 10, 5, 19, 8, 8, 19, 8, 19, 6, 9, 11, 13, 20, 6, 4, 13, 13, 12, 10, 7, 9, 9, 12, 14, 11, 6, 14, 7, 4, 9, 23, 11, 14, 11, 8, 4, 13, 18, 6, 9, 7, 5, 18, 6, 7, 4, 7, 6, 14, 15, 15, 7, 11, 7, 11, 17, 11, 6, 12, 6, 7, 4, 5, 4, 17, 16, 13, 17, 11, 16, 12, 12, 6, 11, 6, 18, 5, 12, 13, 13, 18, 13, 18, 8, 4, 9, 5, 17, 9, 8, 6, 16, 12, 17, 7, 19, 8, 17, 5, 5, 9, 9, 6, 4, 18, 11, 5, 11, 4, 10, 12, 11, 19, 6, 9, 16, 16, 23, 13, 7, 5, 4, 8, 5, 11, 6, 4, 8, 9, 6, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "transform_label = lambda x: {'neg':0,'rdrp':1,'xdxp':2}[x]\n",
    "sequences, labels = [d[1] for d in data], [transform_label(d[2]) for d in data]\n",
    "print(sequences[:5],labels[:5])\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.25, shuffle=True)\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "print(tokenizer(train_sequences[0]))\n",
    "train_tokenized = tokenizer(train_sequences)\n",
    "test_tokenized = tokenizer(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dcc4eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask'],\n",
      "    num_rows: 32976\n",
      "})\n",
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 32976\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)\n",
    "print(train_dataset)\n",
    "train_dataset = train_dataset.add_column(\"labels\", train_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", test_labels)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bad3a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/esm2_t6_8M_UR50D were not used when initializing EsmForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing EsmForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EsmForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of EsmForSequenceClassification were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = max(train_labels + test_labels) + 1  # Add 1 since 0 can be a label\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "\n",
    "#something to try some other time:\n",
    "#from transformers import EsmTokenizer, EsmForSequenceClassification\n",
    "#tokenizer = EsmTokenizer.from_pretrained(model_checkpoint)\n",
    "#model = EsmForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd382bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "batch_size = 8\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-localization\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=True,\n",
    ")\n",
    "from evaluate import load\n",
    "import numpy as np\n",
    "\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438a1ad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-24ed9679b71b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fafa8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rayan/anaconda3/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 32976\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12366\n",
      "  Number of trainable parameters = 7840963\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrayanc\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.19"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/d/work/serratus/palmfold/wandb/run-20221111_181430-1w6gmaol</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/rayanc/huggingface/runs/1w6gmaol\" target=\"_blank\">esm2_t6_8M_UR50D-finetuned-localization</a></strong> to <a href=\"https://wandb.ai/rayanc/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12366' max='12366' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12366/12366 16:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>0.171905</td>\n",
       "      <td>0.958606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.146035</td>\n",
       "      <td>0.965975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.141601</td>\n",
       "      <td>0.969887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10992\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to esm2_t6_8M_UR50D-finetuned-localization/checkpoint-4122\n",
      "Configuration saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-4122/config.json\n",
      "Model weights saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-4122/pytorch_model.bin\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-4122/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-4122/special_tokens_map.json\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-localization/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-localization/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10992\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to esm2_t6_8M_UR50D-finetuned-localization/checkpoint-8244\n",
      "Configuration saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-8244/config.json\n",
      "Model weights saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-8244/pytorch_model.bin\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-8244/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-8244/special_tokens_map.json\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-localization/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-localization/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10992\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to esm2_t6_8M_UR50D-finetuned-localization/checkpoint-12366\n",
      "Configuration saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-12366/config.json\n",
      "Model weights saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-12366/pytorch_model.bin\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-12366/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-localization/checkpoint-12366/special_tokens_map.json\n",
      "tokenizer config file saved in esm2_t6_8M_UR50D-finetuned-localization/tokenizer_config.json\n",
      "Special tokens file saved in esm2_t6_8M_UR50D-finetuned-localization/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from esm2_t6_8M_UR50D-finetuned-localization/checkpoint-12366 (score: 0.9698871906841339).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12366, training_loss=0.13043281034456958, metrics={'train_runtime': 1027.2949, 'train_samples_per_second': 96.3, 'train_steps_per_second': 12.037, 'total_flos': 1135514082546720.0, 'train_loss': 0.13043281034456958, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5c4a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model() \n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c94c71",
   "metadata": {},
   "source": [
    "# Start here if you have the model saved locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "770917a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Cloning https://huggingface.co/rchikhi/esm2_t6_8M_UR50D-finetuned-localization-finetuned-localization into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "# all you need to reload a trained model, mostly copypasted from above\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "num_labels = 3\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"esm2_t6_8M_UR50D-finetuned-localization\", num_labels=num_labels)\n",
    "model_checkpoint = \"esm2_t6_8M_UR50D-finetuned-localization\"\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"esm2_t6_8M_UR50D-finetuned-localization\")\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "batch_size = 8\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=True,\n",
    ")\n",
    "from evaluate import load\n",
    "import numpy as np\n",
    "metric = load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "071677dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "/mnt/d/work/serratus/palmfold/esm2_t6_8M_UR50D-finetuned-localization-finetuned-localization is already a clone of https://huggingface.co/rchikhi/esm2_t6_8M_UR50D-finetuned-localization-finetuned-localization. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4da46434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "PredictionOutput(predictions=array([[ 5.986538 , -2.4479628, -2.8879347]], dtype=float32), label_ids=None, metrics={'test_runtime': 0.98, 'test_samples_per_second': 1.02, 'test_steps_per_second': 1.02})\n"
     ]
    }
   ],
   "source": [
    "# test a prediction with a single protein\n",
    "\n",
    "test_protein = \"LAAKYRCRLRTIAPLVTFAFSLAVPILAAQQDPALPQPQQQSPQTTIRQTVRRVVVDVVVTDSHGKPVRGLTKDDFSVFEDGKPQKILSFDVHDSASDPAFVPPKLPALPANTFVNLPSGPERGPLYVLLYDLLNTEVEDQPQARKQLQKFIKSKPLGTRFAIFVLTDGLHLVQGFTTDRNLLLAAVDPGGSHIPRIFLYGDNFRPYVSGLGALIDIARFLSGLPGRKNLIWFSGSFPYFEDLPMLPGSDPSS\"\n",
    "test_tok  = tokenizer([test_protein])\n",
    "test_ds = Dataset.from_dict(test_tok)\n",
    "predictions = trainer.predict(test_ds)\n",
    "print(np.argmax(predictions.predictions, axis=-1))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "209b8afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 4627\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 1 1 1]\n",
      "4594 33\n",
      "accuracy: 0.9928679489950292\n"
     ]
    }
   ],
   "source": [
    "# predict wolf2018 (totally unseen given that training was serratusL)\n",
    "\n",
    "prots = [] \n",
    "for line in open(\"data/RNAvirome.S2.fa\"): #wolf2018\n",
    "#for line in open(\"palmfold-git/pol/fa/all.fa\"): # palmfold pol db\n",
    "    if line.startswith('>'): continue\n",
    "    prot = line.strip()[:1024]\n",
    "    if len(prot) < 200: continue\n",
    "    prots += [prot]\n",
    "test_tok  = tokenizer(prots)\n",
    "test_ds = Dataset.from_dict(test_tok)\n",
    "predictions = trainer.predict(test_ds)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "print(preds)\n",
    "tp = 0\n",
    "fp = 0\n",
    "for p in preds:\n",
    "    if p > 0:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "print(tp,fp)\n",
    "print(\"accuracy:\",tp/(tp+fp))\n",
    "\n",
    "# wolf2018:\n",
    "# 4594 33\n",
    "#accuracy: 0.9928679489950292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb6504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51cd43dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9848 152\n",
      "accuracy: 0.9848\n"
     ]
    }
   ],
   "source": [
    "# predict some other negs in serratusL unseen before\n",
    "\n",
    "prots = [] \n",
    "for line in open(\"data/other-negs.csv\"):\n",
    "    prots += [line.split(',')[0]]\n",
    "test_tok  = tokenizer(prots)\n",
    "test_ds = Dataset.from_dict(test_tok)\n",
    "predictions = trainer.predict(test_ds)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "tp = 0\n",
    "fp = 0\n",
    "for p in preds:\n",
    "    if p == 0:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "print(tp,fp)\n",
    "print(\"accuracy:\",tp/(tp+fp))\n",
    "# 9848 152\n",
    "# accuracy: 0.9848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "302afc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 4032\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6596159 -2.8863697  2.1669571] DTFYKLNIQEYRKERVAKGIDTNRAINEKDWFKESTRSNVQFNILREILRYKTSDSKCYSSMENNIFDILDQARTITNPILFSGSSELKKIFREARYKPEVANKYNISFIDGFGKDYICNIWYCIVYNSYFSDINFCILTTRELFEHIEFGKIMDDQFVKVSYKPSQSNNVGELSHNYWMQVTLAKDKPCIKTEIKNTDKSDDNQVLLSKATTL\n",
      "[-1.7562011  2.303229  -0.4715117] MSFLEKEAEHVEGFAPELAVVTHGGGEKLEEPLVVRPTSETIIGYMYAKWIKSYRDLPVLINQWANVVRWEMRTRLFLRTLEFYWQEGHTAHATAEEAEEETRRMLDVYADFAENEAAVPVIPGRKSESEKFAGAVRTYSIEAMMGDGKALQSGTSHNLGQNFAKAFDIQYLDKNNELQYCWTTSWGLSTRFIGAIIMTHGDDQGLILPPRLAPIQVVIVPIYKNDEEKSKVMEVVERLRRELAGFRVKVDDR\n",
      "[-2.479008  -2.4677284  4.441613 ] APAHARAPGLRSRAASPTLSIVAPINNSPVQGFRATWIQVNRDWFGRMRARLLERNCVGNIEVKRWRQRSLPDRQKSLSQPFVSAAIHQNGLSGDVRGALRSQPHDGIGDFARLAQALERSVRGPGVEDLLLGFSRRGGAGFGQFFQAIGGGETGADVVDQNSVFAELVGQALYQSHHRGTDGVGEHKIGDRLLRGNRGDGDDASPALALHVRDDFAGEVDRAQKVLLHGLAPFFEGGGEESLGWRAAGVGDT\n",
      "[ 1.4464183  1.8378502 -2.9044936] ALNESPPTGGTSGTTNRRFTSYDRSPTTKLDYAVNRHYDPQQGRFTQVDPAGMKSTSLSNPQTLNLYAYCTNDPINRVDPSGLGFFSFLKKWFKRVWHAAIHAVFTFLQTLLMTGSVHAAFVAGVADFFKELGWPSKGWWPGTPQWNPNAKPILGGGIGPLSRYIIVNFQDTQDTFFIIGRFGFSADELKRLRRAYEKITSDDCRKFFDDTLRMLRQRGEISSPFDFTPDTLQGTLAIATLTQYNSSLTARQV\n",
      "[-0.6005553 -1.9406793  2.3947842] KDLEAILRLRNLGRGVPVLRLDDDVIFRGKQETEQNATANTTIGDLGLFKAIACAVRAYQLRLEDPTVSTFLFSASYNSRALLNPTGDRFEAWSRAFATRVYPALPADPEQIAGICSRSDETEKDEQWNEYAEEHLDESLARQFYGLDTNDLRLNETLEGLTSIGAHPFHSVISGALLCLSDGAILDLPPFSNFRHNVMWIDDHLKYSLHDELEHFTSWDRLHLEYPGVSEARFSEVRVTKKRGSLGFDLKDY\n",
      "[-1.5100927  3.0945497 -1.484786 ] LGRGRACEKLQDTDEMLELDRFFRRWNFGADAASEEAALSPRARAALEAYCRGVNLYFSRHRIPWELRLLGYRPEPWTIADIFLTAKVAGYVGLAQSQADMERFIVECVQNGIDREKLEELFPGQLEGLDEELLRKVRLQERLVPESLKWASALPRMTASNNWVVAGKRTASGKPMLCNDPHLEVNRLPAIWYEAVLRWQADDGPRYAMGATFPGIPGVLIGRTPDLSWGVTYAFMDCVDSWVEECRDGKYRR\n",
      "[ 0.18624562  2.4844074  -2.3917775 ] KVLEQLPKDAHPMDVLRTGVSVLGCIEPEAEDHSAAGARDIADRLIACLPSMLLYWYHFSHNGRRIDVETDDDSIAGHFLHLLHQRPPSKSWVRAMQTSLILYAEHEFNASTFAARVIAGTGSDIYSAITGAIGALRGPKHGGANEEALEIQERYRSPDEAEADIRRRLARKEIIIGFGHPVYTVSDPRNQIIKSVAKQLSDDAGSMNMYDIAERIESVMWEEKNMFPNLDWYSAVSYHMMGVPTEMFTPLFV\n",
      "[-0.5170217 -3.05767    3.2681873] HQAVIAEAKRIAKELGAPSGVLTFEPHPREFFKPDKPPFRLTPFREKLELLEALGVDYVYVLPFDRAFASISAEDFIKEILVEGLNAKHVVVGYDFRFGKNRSGDAELLRELGEKYGFGVTIVPPVVDEDGVVYSSTRIRELILAGDVEEAAKLLGRPYSIEGRVVHGDQRGRTIGFPTANIALGDYLLPAYGVYAVRAGIDDGRGTRWYDGVANIGRRPTFGGKEPLLEVHIFDFDGDLYGKHLRVEFIDFI\n",
      "[-3.674637  -1.4880322  4.6542945] LRLLRTYSEARSRNIRVADWNYATSSYLGSWVSTVALQLHAAIASDRSRRPFESGSYPRRRYLSGYRLPAAEPPVHRRSRTFSRLSRNDLATCLEELPCCRHHGSAYRKVPRSRLLTLRHRHRWRPLCEESRWQRLLRRGVAGPGFIPRTATHAEIHNVYGMENSRATFDGLRKLDPNERPFVLTRASYAGGQRYAATWTGDNSSSWNHLRMTTPMLENLGLSGFAFSGADVGGFAGTPQPDLLTKWLEIAAF\n",
      "[ 0.60793537 -3.369769    2.5743036 ] DGPIEAEVKLDDGTVWRNLVTEEKSKVAETLDEFRGNYRYNLLDEHMRRFNAEVPQIVQWDDHEVRNNWYPGRDLSDPRYTEKSVALLAARAKRAFLEYNPLRYHPDDPERIYRRISYGPLLDVFVLDMRSYRGPNSENRQTTLDAESAFLGAAQLAWLKRALAASRATWKVIASDMPLGLVVPDGKPDVGKDYFEAWANGDDGPPLGRELEIADLLRFIKRNRIRNVVWITADVHYCAAHHYDPARAQFTDF\n",
      "[-3.1391826  3.9978225 -0.9222811] SAFYSYWKGYATVSFPSEKEILFTPTGGILDARLRRHKKKDGIERMLKPTKENPLLDPESPVAAKFVKSLMERSQVKEIGGFIWKVDPDVIKEVAEVMADFITSRVEDVEIGLGGVSLSGLVKGVSVVCAVSQIHSLVSILMSKDPTDVSTSVNWPALFRHRRQWLRWFGLLGADEKVLSALTFDAEDKTGDVAITPLVPIDDEYLGVVPSLAMRSNWPRHLLVLLAKKFGTAYSVYSAGKEDRRLVAFRESH\n",
      "[-2.2336264  0.5603045  1.4840182] TRIPIAAGQMEGHRWRLRELVEHHAVDILQPNVCFCGGYTEAVKAAHLAQAYNLPIANGGGWPLFNMHTMAGLMNGPGWRDAFRESAAAGEGNVDDSRRSRPRADAQSRRAARQRGGKMKIVDIREMTVPIKSNIRNAYIDFSQMTVSVVALITDVVRDGKPVVGFGFNSNGRYAQSGILRERFIPRLLAADPDSLLDEDGDNFDPFKIWNIMMRNEKPGGHGERAVAVGALDMAVWDLVAKIAGEPLWRLLA\n",
      "[-3.5706198   3.8017893  -0.32655513] KTYEVDDVVSFERWLELRDRARKDLFWLGRLLGKGLFHDVHQPICDQFVQKNFDGMYFPGYTLDDVHEMIRRQKRFAEDGTPTREMMLLDPRGFYKSTIDGVDCVQWMLNCPDIRIMIITGFYDLAVKFLGEIKGYFYLPEGGSPSAFQLLFPEYVLTGVDGTSDEPLECPARTHKQKEPTLWVNSIESSLSGWHCDIKKGDDVVTDENSNTPELREKLKEKFDGTDNLLDPWGFTDHIGTRYFTDDWYGTRM\n",
      "[-3.662821  -1.8302372  4.902282 ] ASISHDHCLRYINDDTFRCFNRELYDEWKRCYMGGICDLFDLNLKQEPVYVYDVNGLYPYVRLKYDYPVGEPEEIENPSISRLPNLFGLIKAIVYNDGKVPLGIPCKIGTEFNRLKGRVLYEGTTEELKNLVRLGAKVERIDKVLHYSRRREGKELFGESIEVFDRIKREGTKTGNKGKLGHNSAYGKFGLKWDKYGIDSSDNSSLTIGSFIASYARMETMNLIEYIQNLKGTVYYVDTDSFHTNIELPDDMI\n",
      "[-2.380187    2.6912913  -0.34927854] LESESIEKILSDPKMYNYSIRTGELLGKGKHLLVIDIDLKSDKTFKGIADRLLEIFKGYYTVKTPSGGYHIYVKVESDDKFKSQHLFTLEGKKTTIEILGEKKKAIGPGSIIDNKMYKRMGRLEWDCSLSSKIISREDFVSKLRQGGLELIEEEYIEYPSPDMTVITAYMARKTLLDKILQTLANFKKAINYGQGHVGTSGDDYALLISENKFYDLALAIGIQGSDQAYSDLIQGRVERVMGLRIIPIPYLEN\n",
      "[ 1.3161899 -2.8987193  1.5050594] GAVGSQTGQTALTRIAVIMAAKGGTVADVTVGDCLELLEVAAQVGAGLHGGAHSPLFYQLLRAHGGFGADAPAAMRVFSGRGQPTCEQLIDRYGIQCRPVRDVLVDYLRERQPSVDFSSLQRLAYLLGKLFWADLEAHHPGISSLKLPRDVAAAWKQRVMTRTRTTTTPDGQQVQATTPRLDGRSVLTAVRAFYLDIAEWADDDPARWGPWAVRCPVSASDVSHKKDRSRRKSRMDQRTRERLPVLPALVAWV\n",
      "[-3.1598527 -1.9211497  4.6138873] HAESAGSLGDVFTLNSTRDGKFHVEQVPCWITYTTPKTHDIIRANLNRSPMYSGTIKGTGPRYCPSIEDKVVRFPDKDSHQLFLEPEGRYTDEYYLNGFSTSLPEDVQLKMIRSIPGLENAEIIRPGYAIEYDYIPPTQLKPTLESKLVSGLFFAGQINGTSGYEEAAAQGLIAGINAALKAQGKEPFVLDRSEAYIGVLIDDLVTKGTEEPYRMFTSRAEYRLLLRHDNADQRLTEKAFEVGLVSDERYERF\n",
      "[ 0.7911321 -2.946544   2.034815 ] AYIRMMGAEGLRRATEVAILNANYLAERLDDYYPVLYTGKNGRVAHEFILDLREFKKYGIEVEDIAKRLMDYGFHAPTMSWPVAGTLMIEPTESESKEELDRFCDAMISIREEIQEIEDGKYDKENNVLKNAPHTAEDLTSDEWDHPYSREKAAYPLPWLRNNKFWPSVARIDNAYGDRNLICSCPPMEWYEELTGTQMSGDDPKQMLRELLARAEQRYGKRAHEVEFDVREEENGPIRVEFHNEALTKATVH\n",
      "[-2.4131238 -2.0825634  4.0974374] DWAFRGWTFQEHLFSRRLLIVNGPHGLVSWICQRAEWTEEEYRPSEGLQWISTQEHQGRPTHIRQFNRFPLWPDLISYSQIVTSYSTRALTFDSDVLAAFAGITTVLECSFRCKFIYGLPEAFFDLALLWQPEDGIRRRTGSEQDHNFPSWSWTGWVGRVSYSLMENCTGMWIYHEGLPIWLSPVVTWYCSSSPEHGHSTSDNESSSHRRINDIWTRLYGSGSEPGEQLPSNWRREYEQGIAFYTHPSTPGGR\n",
      "[-2.5343685  3.7626765 -1.2564179] ATKFFEHFLYIAHAMNNMGGQGGGIGLWDEEDGFFYDVLKLPDGRSTPLKVRSMVGLIPLFAVETLEPELLERLPDFKKRLEWFLENRPDLAALISSWHEPGAGERRLLSLVNGERLRRILRRMLDEDEFLSPYGIRSLSKYHKDHPYVFHHDGQTYSVRYEPAESDTGLFGGNSNWRGPIWFPVNYLLIESLQKFHHYYGDDFKVECPTGSGHMMTLKEVAQELSRRLVRLFLADADGRRPAHGISAHTHRD\n",
      "[-0.81187016 -2.743047    3.2101972 ] NKKRPDSVLTVGPVSAAPWGSASILPISWAYIRMMGAEGLRRATEVAILNANYLAERLDDYYPVLYTGKNGRVAHEFILDLREFKKYGIEVEDIAKRLMDYGFHAPTMSWPVAGTLMIEPTESESKEELDRFCDAMISIREEIQEIEDGKYDKENNVLKNAPHTAEDLTSDEWDHPYSREKAAYPLPWLRNNKFWPSVARIDNAYGDRNLICSCPPMEWYEELTGTQMSGDDPKQMLRELLARAEQRYGKRAH\n",
      "[ 0.65626615 -2.417471    1.7565058 ] SDSERFRVTMYDPDAMRKHHNPGRHEYLIAREVLEADVVINLPKLKTHRKAGITCALKNLVGINGHKDYLPHHRKGSPIEGGDEYPGASRLKRLAEDLLDRANRTRGGRMRRLLARLARILIKLAKWLGSDPNLEGSWYGNDTIWRTVLDLNRILRYADKDGKLQDTPQRKVLTIVDGIIAGEGEGPLAPTPKPTGILTAGDNPVAVDWVCALLMGFDPRKIPLVRNAFNDFPWPLVDFGPEDIRVRSNGSRW\n",
      "[-0.9368661 -3.1363606  3.7412524] HGEVTKPETINYRSFKPEKDGLFCEKIFGPVKDWECNCGKYKRIRYRGIVCDRCGVEVTQKKVRRERMGHINLAVPVVHIWFFKSLPSKIGYLLGITTKDLEKIIYYESYVVINPGKTELQKGDLLDEEEYLELEQKLEDEGDNKFIAKMGGEAIKELLKRLDLDELSDELREQLKTETSQQRKKEALKRLRVVEAFRNSGDNGKERNKPEWMVLDVIPVIPPDLRPLVPLDGGRFATSDLNDLYRRVIIRNN\n",
      "[-1.0907646  -0.02279391  1.0251305 ] RLCCHRYEQSFSVVPQRVNESDSLEEEAAVLHPFPRGIYRAIRQSGLRSITKRAFLLGFSLRRRIHDRTFQPDVASLKHNRHVPRHEITCSVAKAKNGCVTSPARRKNLGMKQEALLLTDSNPSSQDRRLAKLLDFFGVPWRSLTATDFALANGAGCETSSKYRLLCSADTFLRLLEALERDPGGMRLWRERVHSAFVYAGDDPEALQKLARRLSGDPGAVIRSINRGAGDFVVSDDLPEFCGVMSGVRVAAS\n",
      "[-2.1943147  2.4996977 -0.4352349] PRGIYRAIRQSGLRSITKRAFLLGFSLRRRIHDRTFQPDVASLKHNRHVPRHEITCSVAKAKNGCVTSPARRKNLGMKQEALLLTDSNPSSQDRRLAKLLDFFGVPWRSLTATDFALANGAGCETSSKYRLLCSADTFLRLLEALERDPGGMRLWRERVHSAFVYAGDDPEALQKLARRLSGDPGAVIRSINRGAGDFVVSDDLPEFCGVMSGVRVAASNANLNSDLVFSASKGSATSIISTGDGAAFVKVEY\n",
      "[-0.04208523 -3.176333    2.9315119 ] EDGPTLSFRGLDNSIYYLLEDDRSRYENYSGCGNTLNCNHPIVRRLIMDSLRYWVEEMHVDGFRFDLASILGRDEDGSVLPNPPVLEDIASDPVLAGTKLIAEAWDAAGLYQVGSFPGDRWKEWNGRFRDDVRRFWRGDPGTVGAFATRLCGSPDLYQHDGREPEQSVNFVTCHDGFTLNDLVSYNRKHNEANGEDNRDGADDNYSWNCGVEGPTDDPAIEALRRRQVKNFLATLLLSQGTPMLLMGDEFRRT\n",
      "[-1.5975734  4.0084133 -2.2034614] PPEENHYGRPGFRSVLQQVAGIYREQREKVAENAQAIHEHVAATLDEAKSGPVTPATLSQVASEMARLFDIRYGGFGTAPKFPHPAAGQFLLARWHDTREDWMREVVEKTLTGMANGGIRDHVGGGFHRYAVDERWIVPHFEKMAYDNSELLHVYLDGYAALGTPLFAEVAHGIVTWVLETLADPARGAFYTSQYADVEFGDDGNYWTWMPDEAFQVIRRVYDVEVPGEMQHDHEKNVLWWKQDPADAAEWQT\n",
      "[ 0.242781 -3.227004  2.840061] SKLEEQPGDDPPLPFSFLTEKITTPQIPCYITHTNPKTHDIIRANLDRSPMYSGKIEGVGPRYCPSIEDKVVRFADKESHQIFLEPEGLDTDEIYPNGISTSLPEDVQLAMLRSIPGLENAKILRPGYAIEYDYIDPRQLRPTLETKKVPGLFLAGQINGTTGYEEAAAQGLVAGINAALKARGEEPFVLKRDEAYIGVLIDDLVTKGTSEPYRMFTSRAEYRLLLRQDNADQRLTPKGHELGLVSEERYERF\n",
      "[ 0.49668226 -3.4755507   2.78696   ] FDEVTARTDLEKLRRGPVKYPRVKKLKRRLLERAFARFQARASAERQAAFEAFCEEEAAWLEDYTLFRALMELNGESEAWDQWPPEHQTPEKARAWLASQPPDQRAQFERRRNFFAYVQWIAFQQWRALRAYAEERGVALMGDIPFGVSYYSADVFFHPEIFDLDWSGGAPPEPVFKDDPFTQKWGQNWGIPLYRWDVMRADDFAWWRQRVRKVRRIFHLFRIDHVLGFYRIYAFPWRPQRNAEFLPLDWEEM\n"
     ]
    }
   ],
   "source": [
    "# predict CFDL\n",
    "\n",
    "prots = [] \n",
    "for line in open(\"data/CFDL-sample.fa\"): \n",
    "    if line.startswith('>'): continue\n",
    "    prot = line.strip()[:1024]\n",
    "    if len(prot) < 200: continue\n",
    "    prots += [prot]\n",
    "test_tok  = tokenizer(prots)\n",
    "test_ds = Dataset.from_dict(test_tok)\n",
    "predictions = trainer.predict(test_ds)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "tp = 0\n",
    "fp = 0\n",
    "for i,p in enumerate(preds):\n",
    "    if p > 0:\n",
    "        print(predictions.predictions[i],prots[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff33ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "0 0\n",
      "2 0\n",
      "2 0\n",
      "1 0\n",
      "0 0\n",
      "2 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 0\n",
      "2 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "0 0\n",
      "2 0\n",
      "2 0\n",
      "1 0\n",
      "0 0\n",
      "2 0\n",
      "2 0\n",
      "0 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "0 0\n",
      "2 0\n",
      "0 0\n",
      "0 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "2 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "1 0\n",
      "0 0\n",
      "431 61\n",
      "accuracy: 0.8760162601626016\n"
     ]
    }
   ],
   "source": [
    "# test accuracy on palmcores decoys\n",
    "\n",
    "prots = [] \n",
    "labels = []\n",
    "for line in open(\"data/palmcores.fa\"): \n",
    "    if line.startswith('>'): \n",
    "        labels += [0 if 'decoy' in line else 1]\n",
    "    else:\n",
    "        prot = line.strip()[:1024]\n",
    "        if len(prot) < 200: continue\n",
    "        prots += [prot]\n",
    "test_tok  = tokenizer(prots)\n",
    "test_ds = Dataset.from_dict(test_tok)\n",
    "#predictions = trainer.predict(test_ds)\n",
    "#preds = np.argmax(predictions.predictions, axis=-1)\n",
    "tp = 0\n",
    "fp = 0\n",
    "for i,p in enumerate(preds):\n",
    "    if labels[i] == 0: #select only decoys\n",
    "        if (labels[i] == 0 and (p == 0 or p == 2)) or \\\n",
    "            (labels[i] > 0 and p > 0):\n",
    "                tp += 1\n",
    "        else:\n",
    "            fp +=1\n",
    "        print(preds[i],labels[i])\n",
    "print(tp,fp)\n",
    "print(\"accuracy:\",tp/(tp+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bec5529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
